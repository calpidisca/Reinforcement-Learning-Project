{"cells":[{"cell_type":"code","source":["filename = \"requirements.txt\"\n","file_content = \"\"\"gymnasium>=0.29.0\n","stable-baselines3>=2.0.0\n","sb3-contrib>=2.0.0\n","numpy>=1.24.0\n","pandas>=2.0.0\n","tqdm>=4.65.0\n","tensorboard>=2.14.0\n"," \"\"\"\n","\n","with open(filename, \"w\") as f:\n","    f.write(file_content)\n","\n","print(f\"파일 '{filename}'이(가) 성공적으로 저장되었습니다.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IBLsIGlPQMe","executionInfo":{"status":"ok","timestamp":1765089437179,"user_tz":-540,"elapsed":4,"user":{"displayName":"cyclone","userId":"12166826990540214817"}},"outputId":"f3d88910-f94c-44d0-e2fa-5091ce0124db"},"id":"9IBLsIGlPQMe","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 'requirements.txt'이(가) 성공적으로 저장되었습니다.\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n","!rm requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IPrg05OiMPiI","executionInfo":{"status":"ok","timestamp":1765089445961,"user_tz":-540,"elapsed":8781,"user":{"displayName":"cyclone","userId":"12166826990540214817"}},"outputId":"4881e413-f437-4dfb-c302-093794e1260a"},"id":"IPrg05OiMPiI","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium>=0.29.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.2.2)\n","Requirement already satisfied: stable-baselines3>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.7.1)\n","Requirement already satisfied: sb3-contrib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.7.1)\n","Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n","Requirement already satisfied: tensorboard>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.19.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.29.0->-r requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.29.0->-r requirements.txt (line 1)) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.29.0->-r requirements.txt (line 1)) (0.0.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (2.9.0+cu126)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 5)) (2025.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (1.76.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (3.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (25.0)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 7)) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.14.0->-r requirements.txt (line 7)) (3.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (3.2.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\n","Looking in indexes: https://download.pytorch.org/whl/cu124\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dd6ca03b","executionInfo":{"status":"ok","timestamp":1765089445967,"user_tz":-540,"elapsed":5,"user":{"displayName":"cyclone","userId":"12166826990540214817"}},"outputId":"628503cb-c66b-4d92-a473-c9967d857fb7"},"source":["import torch\n","\n","if torch.cuda.is_available():\n","    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    print(\"CUDA is NOT available to PyTorch.\")\n","    print(\"This could be due to a missing or misconfigured CUDA toolkit, or driver issues.\")"],"id":"dd6ca03b","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available! Using GPU: NVIDIA L4\n"]}]},{"cell_type":"code","execution_count":35,"id":"ff4a3a40","metadata":{"id":"ff4a3a40","executionInfo":{"status":"ok","timestamp":1765089446006,"user_tz":-540,"elapsed":32,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/config.py\n","\"\"\"Experiment configuration for superpermutation RL research.\"\"\"\n","\n","from typing import Dict, List, Tuple\n","\n","# Permutation sizes to test\n","N_LIST: List[int] = [5] #3,4,\n","\n","# Environment types\n","ENV_TYPES: List[str] = [ \"word_cost\",\"symbol\"]\n","\n","# Algorithms to test\n","ALGOS: List[str] = [\"ppo\"   ] #\"maskable_ppo\",\"dqn_dueling\", \"a2c\",\"dqn\",\n","\n","# Random seeds for experiments\n","SEEDS: List[int] = [0] #0, 1, 2,, , 123, 999 42\n","\n","# Hyperparameter grids (for learning algorithms only)\n","HYPER_GRIDS: Dict[str, Dict[str, List[float]]] = {\n","    \"ppo\": {\n","        \"learning_rate\": [2e-4],\n","        \"gamma\": [0.99],\n","    },\n","    \"dqn\": {\n","        \"learning_rate\": [1e-4],\n","        \"gamma\": [0.99],\n","    },\n","}\n","\n","# Total timesteps per algorithm\n","TIMESTEPS: Dict[str, int] = {\n","    \"ppo\": 2_200_000,\n","    \"dqn\": 2_200_000,\n","}\n","\n","# Episodes for non-learning baselines\n","BASELINE_EPISODES: Dict[str, int] = {\n","    \"random\": 300,\n","    \"greedy\": 300,\n","}\n","\n","# Conditions for skipping certain algorithm/environment combinations\n","# Format: (algo_name, env_type, n) -> skip\n","SKIP_CONDITIONS: List[Tuple[str, str, int]] = [\n","    # Skip DQN variants for word_cost and n=6 (too heavy)\n","    (\"dqn\", \"word_cost\", 6),\n","\n","]\n","\n","\n","def should_skip(algo_name: str, env_type: str, n: int) -> bool:\n","    \"\"\"\n","    Check if a combination should be skipped.\n","\n","    Args:\n","        algo_name: Algorithm name\n","        env_type: Environment type\n","        n: Permutation size\n","\n","    Returns:\n","        True if should skip, False otherwise\n","    \"\"\"\n","    return (algo_name, env_type, n) in SKIP_CONDITIONS\n","\n"]},{"cell_type":"code","execution_count":36,"id":"8a1c6596","metadata":{"id":"8a1c6596","executionInfo":{"status":"ok","timestamp":1765089446012,"user_tz":-540,"elapsed":1,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/callbacks.py\n","\"\"\"Stable-Baselines3 callbacks for superpermutation training.\"\"\"\n","\n","import os\n","import json\n","import numpy as np\n","from stable_baselines3.common.callbacks import BaseCallback\n","from typing import Dict, Any, Optional\n","\n","\n","\n","\n","class SuperpermEpisodeCallback(BaseCallback):\n","    \"\"\"\n","    Callback to log episode-level metrics for superpermutation environments.\n","\n","    Logs:\n","    - superperm/final_length\n","    - superperm/success (0/1)\n","    - superperm/coverage_ratio\n","    - superperm/episode_steps\n","    - superperm/new_perms_total (if available)\n","    - superperm/duplicate_action_ratio\n","    - superperm/episode_return\n","    - superperm/best_final_length_so_far\n","    \"\"\"\n","\n","    def __init__(self, verbose: int = 0, save_episodes_dir: Optional[str] = None, top_k: int = 5):\n","        super().__init__(verbose)\n","        self.best_final_length_so_far = float(\"inf\")\n","        self.episode_count = 0\n","        self.episode_actions = []  # Track actions for duplicate ratio\n","        self.episode_return = 0.0\n","        self.episode_steps = 0\n","        self.save_episodes_dir = save_episodes_dir\n","        self.top_k = top_k  # Number of top episodes to save\n","        self.top_episodes = []  # List of (final_length, episode_data) tuples, sorted by length\n","        if self.save_episodes_dir:\n","            os.makedirs(self.save_episodes_dir, exist_ok=True)\n","\n","    def _on_step(self) -> bool:\n","        \"\"\"Called at each step.\"\"\"\n","        # Track actions for duplicate ratio\n","        if self.locals.get(\"actions\") is not None:\n","            action = self.locals[\"actions\"][0] if isinstance(self.locals[\"actions\"], (list, np.ndarray)) else self.locals[\"actions\"]\n","            self.episode_actions.append(int(action))\n","\n","        # Accumulate reward\n","        if \"rewards\" in self.locals:\n","            reward = self.locals[\"rewards\"][0] if isinstance(self.locals[\"rewards\"], (list, np.ndarray)) else self.locals[\"rewards\"]\n","            self.episode_return += float(reward)\n","\n","        self.episode_steps += 1\n","\n","        # Check if episode is done\n","        dones = self.locals.get(\"dones\", [False])\n","        terminated = self.locals.get(\"terminated\", [False])\n","        truncated = self.locals.get(\"truncated\", [False])\n","\n","        # Check if any episode ended\n","        if isinstance(dones, (list, np.ndarray)):\n","            done = bool(dones[0]) if len(dones) > 0 else False\n","        else:\n","            done = bool(dones)\n","\n","        if isinstance(terminated, (list, np.ndarray)):\n","            term = bool(terminated[0]) if len(terminated) > 0 else False\n","        else:\n","            term = bool(terminated)\n","\n","        if isinstance(truncated, (list, np.ndarray)):\n","            trunc = bool(truncated[0]) if len(truncated) > 0 else False\n","        else:\n","            trunc = bool(truncated)\n","\n","        if done or term or trunc:\n","            self._on_episode_end()\n","\n","        return True\n","\n","    def _on_episode_end(self) -> None:\n","        \"\"\"Called when an episode ends.\"\"\"\n","        # Get info from the environment\n","        infos = self.locals.get(\"infos\", [{}])\n","        if isinstance(infos, (list, np.ndarray)) and len(infos) > 0:\n","            info = infos[0]\n","        else:\n","            info = {}\n","\n","        # Extract metrics from info\n","        final_length = info.get(\"final_length\", self.episode_steps)\n","        success = 1 if info.get(\"success\", False) else 0\n","        coverage_ratio = info.get(\"coverage_ratio\", 0.0)\n","        sequence = info.get(\"sequence\", [])\n","\n","        # Compute duplicate action ratio\n","        if len(self.episode_actions) > 1:\n","            unique_actions = len(set(self.episode_actions))\n","            duplicate_ratio = 1.0 - (unique_actions / len(self.episode_actions))\n","        else:\n","            duplicate_ratio = 0.0\n","\n","        # Update best final length\n","        if success and final_length < self.best_final_length_so_far:\n","            self.best_final_length_so_far = final_length\n","\n","        # Log metrics\n","        self.logger.record(\"superperm/final_length\", float(final_length))\n","        self.logger.record(\"superperm/success\", float(success))\n","        self.logger.record(\"superperm/coverage_ratio\", float(coverage_ratio))\n","        self.logger.record(\"superperm/episode_steps\", float(self.episode_steps))\n","        self.logger.record(\"superperm/episode_return\", float(self.episode_return))\n","        self.logger.record(\"superperm/duplicate_action_ratio\", float(duplicate_ratio))\n","        self.logger.record(\"superperm/best_final_length_so_far\", float(self.best_final_length_so_far))\n","\n","        # New perms total (if available in info)\n","        if \"new_perms_total\" in info:\n","            self.logger.record(\"superperm/new_perms_total\", float(info[\"new_perms_total\"]))\n","\n","        # Save episode info if directory is provided (for successful episodes)\n","        # Only keep top-k shortest episodes\n","        if self.save_episodes_dir and success and sequence:\n","            episode_data = {\n","                \"episode\": self.episode_count,\n","                \"final_length\": int(final_length),\n","                \"episode_return\": float(self.episode_return),\n","                \"sequence\": list(sequence) if isinstance(sequence, (list, tuple)) else sequence,\n","                \"success\": bool(success),\n","                \"coverage_ratio\": float(coverage_ratio),\n","            }\n","\n","            # Add to top episodes list\n","            self.top_episodes.append((final_length, episode_data))\n","\n","            # Sort by final_length (ascending), then by episode_return (descending)\n","            self.top_episodes.sort(key=lambda x: (x[0], -x[1][\"episode_return\"]))\n","\n","            # Keep only top-k\n","            if len(self.top_episodes) > self.top_k:\n","                self.top_episodes = self.top_episodes[:self.top_k]\n","\n","            # Save all top-k episodes\n","            self._save_top_episodes()\n","\n","        # Reset episode tracking\n","        self.episode_count += 1\n","        self.episode_actions = []\n","        self.episode_return = 0.0\n","        self.episode_steps = 0\n","\n","    def _save_top_episodes(self) -> None:\n","        \"\"\"Save the top-k episodes to disk.\"\"\"\n","        if not self.save_episodes_dir:\n","            return\n","\n","        # Remove old episode files\n","        try:\n","            for file in os.listdir(self.save_episodes_dir):\n","                if file.startswith(\"episode_\") and file.endswith(\".json\"):\n","                    os.remove(os.path.join(self.save_episodes_dir, file))\n","        except (OSError, FileNotFoundError):\n","            pass  # Directory might not exist or be empty\n","\n","        # Save current top-k episodes\n","        for rank, (final_length, episode_data) in enumerate(self.top_episodes, 1):\n","            episode_data[\"rank\"] = rank\n","            # Convert numpy types to Python native types for JSON serialization\n","            episode_data_serializable = convert_numpy_types(episode_data)\n","            episode_path = os.path.join(self.save_episodes_dir, f\"episode_{episode_data['episode']}.json\")\n","            with open(episode_path, \"w\") as f:\n","                json.dump(episode_data_serializable, f, indent=2)\n","\n"]},{"cell_type":"code","execution_count":37,"id":"6cd54f06","metadata":{"id":"6cd54f06","executionInfo":{"status":"ok","timestamp":1765089446013,"user_tz":-540,"elapsed":1,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/algorithms/greedy_policy.py\n","\"\"\"Greedy policy baseline.\"\"\"\n","\n","import os\n","import csv\n","import numpy as np\n","import gymnasium as gym\n","from tqdm import tqdm\n","\n","\n","\n","\n","def run_greedy(\n","    env: gym.Env,\n","    total_episodes: int,\n","    max_steps_per_episode: int,\n","    log_dir: str,\n","    seed: int,\n",") -> None:\n","    \"\"\"\n","    Run greedy policy baseline.\n","\n","    For SymbolEnv: selects action that maximizes expected new permutations.\n","    For WordEnv: selects action with minimum cost among uncovered permutations.\n","\n","    Args:\n","        env: Gymnasium environment\n","        total_episodes: Number of episodes to run\n","        max_steps_per_episode: Maximum steps per episode\n","        log_dir: Directory to save logs\n","        seed: Random seed\n","    \"\"\"\n","    os.makedirs(log_dir, exist_ok=True)\n","\n","    # Set seed\n","    np.random.seed(seed)\n","\n","    # CSV file for episode metrics\n","    csv_path = os.path.join(log_dir, \"progress.csv\")\n","\n","    # Field names matching SB3 format\n","    fieldnames = [\n","        \"episode\",\n","        \"final_length\",\n","        \"success\",\n","        \"coverage_ratio\",\n","        \"episode_steps\",\n","        \"episode_return\",\n","        \"covered_permutations\",\n","    ]\n","\n","    # Detect environment type\n","    detected_env_type = detect_env_type(env)\n","    # Map to internal representation for greedy action selection\n","    env_type = \"word\" if detected_env_type == \"word_cost\" else \"symbol\"\n","\n","    with open(csv_path, \"w\", newline=\"\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","        for episode in tqdm(range(total_episodes), desc=\"Greedy policy episodes\"):\n","            # Reset with seed offset\n","            obs, info = env.reset(seed=seed + episode)\n","\n","            episode_return = 0.0\n","            episode_steps = 0\n","            done = False\n","\n","            while not done and episode_steps < max_steps_per_episode:\n","                if env_type == \"symbol\":\n","                    action = _greedy_action_symbol(env, obs)\n","                elif env_type == \"word\":\n","                    action = _greedy_action_word(env, obs)\n","                else:\n","                    # Fallback to random\n","                    action = env.action_space.sample()\n","\n","                obs, reward, terminated, truncated, info = env.step(action)\n","\n","                episode_return += reward\n","                episode_steps += 1\n","                done = terminated or truncated\n","\n","            # Write episode metrics\n","            writer.writerow({\n","                \"episode\": episode,\n","                \"final_length\": info.get(\"final_length\", len(env.string) if hasattr(env, \"string\") else 0),\n","                \"success\": 1 if info.get(\"success\", False) else 0,\n","                \"coverage_ratio\": info.get(\"coverage_ratio\", 0.0),\n","                \"episode_steps\": episode_steps,\n","                \"episode_return\": episode_return,\n","                \"covered_permutations\": info.get(\"covered_permutations\", 0),\n","            })\n","            f.flush()\n","\n","    # Save metadata\n","    n = env.n if hasattr(env, \"n\") else 0\n","    metadata = create_metadata(\n","        env_type=detected_env_type,\n","        n=n,\n","        algo_name=\"greedy\",\n","        hyperparams={},\n","        seed=seed,\n","        total_episodes=total_episodes,\n","    )\n","    save_metadata(log_dir, metadata)\n","\n","\n","def _greedy_action_symbol(env: gym.Env, obs: dict) -> int:\n","    \"\"\"\n","    Greedy action selection for symbol environment.\n","\n","    For each possible action, estimate the number of new permutations\n","    that would be discovered, and select the action with the highest score.\n","    \"\"\"\n","    best_action = 0\n","    best_score = float(\"-inf\")\n","\n","    # Create a temporary copy of coverage for simulation\n","    temp_coverage = env.coverage.copy()\n","    temp_string = env.string.copy()\n","\n","    for action in range(env.action_space.n):\n","        # Simulate adding this symbol\n","        symbol = action + 1\n","        test_string = temp_string + [symbol]\n","\n","        # Estimate new permutations (simplified: check if this creates new length-n substrings)\n","        # We'll use a heuristic: count how many new permutations might be formed\n","        # by checking the last n symbols\n","        new_perms_estimate = 0\n","        if len(test_string) >= env.n:\n","            # Check the last n symbols\n","            last_n = tuple(test_string[-env.n:])\n","            if last_n in env.perms:\n","                idx = env.perms.index(last_n)\n","                if not temp_coverage[idx]:\n","                    new_perms_estimate = 1\n","\n","        # Score: new_perms - small length penalty\n","        score = new_perms_estimate - 0.01  # Small penalty for length\n","\n","        if score > best_score:\n","            best_score = score\n","            best_action = action\n","\n","    return best_action\n","\n","\n","def _greedy_action_word(env: gym.Env, obs: dict) -> int:\n","    \"\"\"\n","    Greedy action selection for word environment.\n","\n","    Select the action (permutation) with minimum cost among uncovered ones.\n","    If all are covered, select the one with minimum cost.\n","    \"\"\"\n","    coverage = obs[\"coverage\"]\n","    costs = obs[\"costs\"]\n","\n","    # Prefer uncovered permutations\n","    uncovered_mask = coverage == 0\n","    uncovered_costs = costs.copy()\n","    uncovered_costs[~uncovered_mask] = float(\"inf\")  # Mask covered ones\n","\n","    if np.any(uncovered_mask):\n","        # Select uncovered permutation with minimum cost\n","        best_action = int(np.argmin(uncovered_costs))\n","    else:\n","        # All covered, select minimum cost overall\n","        best_action = int(np.argmin(costs))\n","\n","    return best_action\n","\n","\n"]},{"cell_type":"code","execution_count":38,"id":"80d20957","metadata":{"id":"80d20957","executionInfo":{"status":"ok","timestamp":1765089446015,"user_tz":-540,"elapsed":1,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/algorithms/random_policy.py\n","\"\"\"Random policy baseline.\"\"\"\n","\n","import os\n","import csv\n","import numpy as np\n","import gymnasium as gym\n","from tqdm import tqdm\n","\n","\n","\n","\n","def run_random(\n","    env: gym.Env,\n","    total_episodes: int,\n","    max_steps_per_episode: int,\n","    log_dir: str,\n","    seed: int,\n",") -> None:\n","    \"\"\"\n","    Run random policy baseline.\n","\n","    Args:\n","        env: Gymnasium environment\n","        total_episodes: Number of episodes to run\n","        max_steps_per_episode: Maximum steps per episode\n","        log_dir: Directory to save logs\n","        seed: Random seed\n","    \"\"\"\n","    os.makedirs(log_dir, exist_ok=True)\n","\n","    # Set seed\n","    np.random.seed(seed)\n","\n","    # CSV file for episode metrics\n","    csv_path = os.path.join(log_dir, \"progress.csv\")\n","\n","    # Field names matching SB3 format\n","    fieldnames = [\n","        \"episode\",\n","        \"final_length\",\n","        \"success\",\n","        \"coverage_ratio\",\n","        \"episode_steps\",\n","        \"episode_return\",\n","        \"covered_permutations\",\n","    ]\n","\n","    with open(csv_path, \"w\", newline=\"\") as f:\n","        writer = csv.DictWriter(f, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","        for episode in tqdm(range(total_episodes), desc=\"Random policy episodes\"):\n","            # Reset with seed offset\n","            obs, info = env.reset(seed=seed + episode)\n","\n","            episode_return = 0.0\n","            episode_steps = 0\n","            done = False\n","\n","            while not done and episode_steps < max_steps_per_episode:\n","                # Sample random action\n","                action = env.action_space.sample()\n","                obs, reward, terminated, truncated, info = env.step(action)\n","\n","                episode_return += reward\n","                episode_steps += 1\n","                done = terminated or truncated\n","\n","            # Write episode metrics\n","            writer.writerow({\n","                \"episode\": episode,\n","                \"final_length\": info.get(\"final_length\", len(env.string) if hasattr(env, \"string\") else 0),\n","                \"success\": 1 if info.get(\"success\", False) else 0,\n","                \"coverage_ratio\": info.get(\"coverage_ratio\", 0.0),\n","                \"episode_steps\": episode_steps,\n","                \"episode_return\": episode_return,\n","                \"covered_permutations\": info.get(\"covered_permutations\", 0),\n","            })\n","            f.flush()\n","\n","    # Save metadata\n","    env_type = detect_env_type(env)\n","    n = env.n if hasattr(env, \"n\") else 0\n","    metadata = create_metadata(\n","        env_type=env_type,\n","        n=n,\n","        algo_name=\"random\",\n","        hyperparams={},\n","        seed=seed,\n","        total_episodes=total_episodes,\n","    )\n","    save_metadata(log_dir, metadata)\n","\n","\n"]},{"cell_type":"code","execution_count":39,"id":"7f12fae4","metadata":{"id":"7f12fae4","executionInfo":{"status":"ok","timestamp":1765089446026,"user_tz":-540,"elapsed":1,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/envs/symbol_env.py\n","\"\"\"Symbol-based superpermutation environment.\"\"\"\n","\n","import math\n","import numpy as np\n","import gymnasium as gym\n","from gymnasium import spaces\n","from typing import Dict, Any, Optional\n","\n","\n","\n","class SymbolSuperpermEnv(gym.Env):\n","    \"\"\"\n","    Symbol-based superpermutation environment.\n","\n","    At each step, the agent adds one symbol (1 to n) to the sequence.\n","    The goal is to construct a sequence that contains all n! permutations\n","    as contiguous substrings while minimizing the total length.\n","    \"\"\"\n","\n","    metadata = {\"render_modes\": []}\n","\n","    def __init__(\n","        self,\n","        n: int = 4,\n","        max_length: int | None = None,\n","        max_steps: int | None = None,\n","        lambda_length_penalty: float = 0.01,\n","        alpha_new_perm_reward: float = 5.0,\n","        goal_bonus: float = 200.0,\n","        length_penalty_at_goal: float = 0.0,\n","    ):\n","        \"\"\"\n","        Initialize the symbol-based superpermutation environment.\n","\n","        Args:\n","            n: Alphabet size (permutations of {1, 2, ..., n})\n","            max_length: Maximum allowed sequence length (default: (n/2) * n!)\n","            max_steps: Maximum number of steps (default: max_length)\n","            lambda_length_penalty: Penalty per step\n","            alpha_new_perm_reward: Reward per newly discovered permutation\n","            goal_bonus: Bonus reward when all permutations are covered\n","            length_penalty_at_goal: Additional penalty based on final length at goal\n","        \"\"\"\n","        super().__init__()\n","\n","        self.n = n\n","        self.alphabet = list(range(1, n + 1))\n","        self.perms = get_all_permutations(n)\n","        self.m = len(self.perms)  # n!\n","\n","        # Set defaults\n","        if max_length is None:\n","            max_length = int((n/2) * math.factorial(n))\n","        if max_steps is None:\n","            max_steps = 2*max_length\n","\n","        self.max_length = max_length\n","        self.max_steps = max_steps\n","        self.lambda_length_penalty = lambda_length_penalty\n","        self.alpha_new_perm_reward = alpha_new_perm_reward\n","        self.goal_bonus = goal_bonus\n","        self.length_penalty_at_goal = length_penalty_at_goal\n","\n","        # Internal state\n","        self.string: list[int] = []\n","        self.coverage: np.ndarray = np.zeros(self.m, dtype=bool)\n","        self.step_count: int = 0\n","\n","        # Action space: choose one symbol from {1, ..., n}\n","        self.action_space = spaces.Discrete(n)\n","\n","        # Observation space\n","        self.observation_space = spaces.Dict({\n","            \"suffix\": spaces.MultiDiscrete([n + 1] * (n - 1)),  # 0-padded, values in {0,...,n}\n","            \"coverage\": spaces.MultiBinary(self.m),\n","            \"length\": spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),\n","        })\n","\n","    def _get_observation(self) -> Dict[str, Any]:\n","        \"\"\"Build the current observation.\"\"\"\n","        # Suffix: last (n-1) symbols, 0-padded\n","        suffix = np.zeros(self.n - 1, dtype=np.int32)\n","        if len(self.string) > 0:\n","            suffix_start = max(0, len(self.string) - (self.n - 1))\n","            suffix_len = len(self.string) - suffix_start\n","            suffix[-suffix_len:] = self.string[suffix_start:]\n","\n","        # Coverage: boolean array\n","        coverage = self.coverage.copy().astype(np.int8)\n","\n","        # Length: normalized to [0, 1]\n","        length_norm = np.array([min(1.0, len(self.string) / self.max_length)], dtype=np.float32)\n","\n","        return {\n","            \"suffix\": suffix,\n","            \"coverage\": coverage,\n","            \"length\": length_norm,\n","        }\n","\n","    def reset(\n","        self,\n","        seed: Optional[int] = None,\n","        options: Optional[dict] = None,\n","    ) -> tuple[Dict[str, Any], Dict[str, Any]]:\n","        \"\"\"Reset the environment.\"\"\"\n","        super().reset(seed=seed)\n","\n","        self.string = []\n","        self.coverage[:] = False\n","        self.step_count = 0\n","\n","        obs = self._get_observation()\n","        info = {\"n\": self.n}\n","\n","        return obs, info\n","\n","    def step(self, action: int) -> tuple[Dict[str, Any], float, bool, bool, Dict[str, Any]]:\n","        \"\"\"\n","        Execute one step.\n","\n","        Returns:\n","            observation, reward, terminated, truncated, info\n","        \"\"\"\n","        # Validate action\n","        if not self.action_space.contains(action):\n","            raise ValueError(f\"Invalid action: {action}\")\n","\n","        # Map action to symbol: action ∈ {0,...,n-1} -> symbol ∈ {1,...,n}\n","        symbol = action + 1\n","\n","        # Append symbol to string\n","        self.string.append(symbol)\n","        self.step_count += 1\n","\n","        # Update coverage\n","        delta_new_perms = update_coverage_for_string(\n","            string=self.string,\n","            n=self.n,\n","            perms=self.perms,\n","            coverage=self.coverage,\n","            search_window=2 * self.n,  # Only check recent suffix\n","        )\n","\n","        # Compute reward\n","        new_perms_reward = self.alpha_new_perm_reward * delta_new_perms\n","        step_length_penalty = -self.lambda_length_penalty\n","        reward = new_perms_reward + step_length_penalty\n","\n","        # Check termination conditions\n","        success = False\n","        truncated = False\n","        terminated = False\n","\n","        if self.coverage.sum() == self.m:\n","            # All permutations covered\n","            success = True\n","            terminated = True\n","            final_length = len(self.string)\n","            reward += self.goal_bonus - self.length_penalty_at_goal * final_length\n","        elif len(self.string) > self.max_length or self.step_count >= self.max_steps:\n","            truncated = True\n","            terminated = True\n","            reward-=100\n","        else:\n","            terminated = False\n","\n","        # Build observation\n","        obs = self._get_observation()\n","\n","        # Build info\n","        info = {\n","            \"n\": self.n,\n","            \"step_count\": self.step_count,\n","            \"current_length\": len(self.string),\n","            \"coverage_ratio\": float(self.coverage.sum()) / float(self.m),\n","            \"success\": success,\n","            \"truncated\": truncated,\n","        }\n","\n","        if terminated or truncated:\n","            info[\"final_length\"] = len(self.string)\n","            info[\"sequence\"] = list(self.string)\n","            info[\"covered_permutations\"] = int(self.coverage.sum())\n","\n","        return obs, reward, terminated, truncated, info\n","\n","\n"]},{"cell_type":"code","execution_count":40,"id":"b13fd9f2","metadata":{"id":"b13fd9f2","executionInfo":{"status":"ok","timestamp":1765089446040,"user_tz":-540,"elapsed":3,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/envs/utils.py\n","\"\"\"Utility functions for superpermutation environments.\"\"\"\n","\n","import numpy as np\n","from typing import List, Tuple\n","from itertools import permutations\n","\n","\n","def get_all_permutations(n: int) -> List[Tuple[int, ...]]:\n","    \"\"\"\n","    Generate all permutations of the alphabet {1, 2, ..., n}.\n","\n","    Args:\n","        n: Size of the alphabet\n","\n","    Returns:\n","        List of all permutations as tuples\n","    \"\"\"\n","    alphabet = list(range(1, n + 1))\n","    return list(permutations(alphabet))\n","\n","\n","def max_overlap(seq: List[int], word: List[int]) -> int:\n","    \"\"\"\n","    Compute the maximum overlap length between seq and word.\n","\n","    The overlap is the length ℓ such that the last ℓ symbols of seq\n","    equal the first ℓ symbols of word.\n","\n","    Args:\n","        seq: Current sequence\n","        word: Word to check overlap with\n","\n","    Returns:\n","        Maximum overlap length (0 to min(len(seq), len(word)))\n","    \"\"\"\n","    if len(seq) == 0 or len(word) == 0:\n","        return 0\n","\n","    max_len = min(len(seq), len(word))\n","    for overlap_len in range(max_len, 0, -1):\n","        if seq[-overlap_len:] == word[:overlap_len]:\n","            return overlap_len\n","    return 0\n","\n","\n","def merge_with_overlap(seq: List[int], word: List[int]) -> List[int]:\n","    \"\"\"\n","    Merge word into seq using maximum overlap.\n","\n","    Args:\n","        seq: Current sequence\n","        word: Word to merge\n","\n","    Returns:\n","        Merged sequence: seq + word[overlap:]\n","    \"\"\"\n","    overlap = max_overlap(seq, word)\n","    return seq + word[overlap:]\n","\n","\n","def update_coverage_for_string(\n","    string: List[int],\n","    n: int,\n","    perms: List[Tuple[int, ...]],\n","    coverage: np.ndarray,\n","    search_window: int | None = None,\n",") -> int:\n","    \"\"\"\n","    Update coverage array by scanning string for contiguous substrings of length n.\n","\n","    Args:\n","        string: The sequence to scan\n","        n: Length of permutations\n","        perms: List of all permutations (tuples)\n","        coverage: Boolean array of shape (len(perms),) to update\n","        search_window: If not None, only scan the last search_window symbols\n","\n","    Returns:\n","        Number of newly discovered permutations (positions that changed from False to True)\n","    \"\"\"\n","    if len(string) < n:\n","        return 0\n","\n","    # Determine search range\n","    if search_window is not None:\n","        start_idx = max(0, len(string) - search_window)\n","    else:\n","        start_idx = 0\n","\n","    delta_new = 0\n","    # Scan all length-n substrings in the search window\n","    for i in range(start_idx, len(string) - n + 1):\n","        substring = tuple(string[i:i+n])\n","        # Find index in perms\n","        try:\n","            idx = perms.index(substring)\n","            if not coverage[idx]:\n","                coverage[idx] = True\n","                delta_new += 1\n","        except ValueError:\n","            # Substring is not a valid permutation, skip\n","            pass\n","\n","    return delta_new\n","\n","\n","def flatten_symbol_observation(obs: dict, n: int, m: int) -> np.ndarray:\n","    \"\"\"\n","    Flatten symbol environment observation for neural networks.\n","\n","    Args:\n","        obs: Observation dict with keys \"suffix\", \"coverage\", \"length\"\n","        n: Alphabet size\n","        m: Number of permutations\n","\n","    Returns:\n","        1D numpy array\n","    \"\"\"\n","    suffix = obs[\"suffix\"].astype(np.float32)\n","    coverage = obs[\"coverage\"].astype(np.float32)\n","    length = obs[\"length\"].astype(np.float32)\n","    return np.concatenate([suffix, coverage, length])\n","\n","\n","def flatten_word_observation(obs: dict, n: int, m: int) -> np.ndarray:\n","    \"\"\"\n","    Flatten word environment observation for neural networks.\n","\n","    Args:\n","        obs: Observation dict with keys \"coverage\", \"costs\", \"length\"\n","        n: Alphabet size\n","        m: Number of permutations\n","\n","    Returns:\n","        1D numpy array\n","    \"\"\"\n","    coverage = obs[\"coverage\"].astype(np.float32)\n","    costs = obs[\"costs\"].astype(np.float32)\n","    length = obs[\"length\"].astype(np.float32)\n","    return np.concatenate([coverage, costs, length])\n","\n","\n","def canonicalize_superperm(sequence: List[int], n: int) -> List[int]:\n","    \"\"\"\n","    Canonicalize a superpermutation by relabeling to a standard form.\n","\n","    Approach:\n","    1. Find the first contiguous block of length n that is a permutation of {1,...,n}\n","    2. Use that block to define a relabeling mapping\n","    3. Apply the mapping to the entire sequence\n","\n","    Args:\n","        sequence: The superpermutation sequence\n","        n: Alphabet size\n","\n","    Returns:\n","        Canonicalized sequence\n","    \"\"\"\n","    if len(sequence) < n:\n","        return sequence.copy()\n","\n","    # Find first permutation block\n","    mapping = None\n","    for i in range(len(sequence) - n + 1):\n","        block = sequence[i:i+n]\n","        # Check if block is a permutation of {1,...,n}\n","        if set(block) == set(range(1, n + 1)) and len(block) == len(set(block)):\n","            # Create mapping: block[j] -> j+1\n","            mapping = {block[j]: j + 1 for j in range(n)}\n","            break\n","\n","    # If no permutation block found, return original\n","    if mapping is None:\n","        return sequence.copy()\n","\n","    # Apply mapping\n","    canonical = [mapping.get(symbol, symbol) for symbol in sequence]\n","    return canonical\n","\n","\n"]},{"cell_type":"code","execution_count":41,"id":"94a48713","metadata":{"id":"94a48713","executionInfo":{"status":"ok","timestamp":1765089446057,"user_tz":-540,"elapsed":2,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/envs/word_env_cost.py\n","\"\"\"Word-based superpermutation environment with cost state.\"\"\"\n","\n","import math\n","import numpy as np\n","import gymnasium as gym\n","from gymnasium import spaces\n","from typing import Dict, Any, Optional\n","\n","\n","\n","class WordCostSuperpermEnv(gym.Env):\n","    \"\"\"\n","    Word-based superpermutation environment with cost state.\n","\n","    At each step, the agent selects one permutation to add to the sequence.\n","    The cost of adding a permutation is (n - overlap), where overlap is\n","    the maximum overlap between the current sequence and the selected permutation.\n","    \"\"\"\n","\n","    metadata = {\"render_modes\": []}\n","\n","    def __init__(\n","        self,\n","        n: int = 4,\n","        max_length: int | None = None,\n","        max_steps: int | None = None,\n","        alpha_new_perm_reward: float = 5.0,\n","        goal_bonus: float = 200.0,\n","        length_penalty_at_goal: float = 0.0,\n","    ):\n","        \"\"\"\n","        Initialize the word-based superpermutation environment.\n","\n","        Args:\n","            n: Alphabet size (permutations of {1, 2, ..., n})\n","            max_length: Maximum allowed sequence length (default: (n/2) * n!)\n","            max_steps: Maximum number of steps (default: 3 * n!)\n","            alpha_new_perm_reward: Reward per newly discovered permutation\n","            goal_bonus: Bonus reward when all permutations are covered\n","            length_penalty_at_goal: Additional penalty based on final length at goal\n","        \"\"\"\n","        super().__init__()\n","\n","        self.n = n\n","        self.perms = get_all_permutations(n)\n","        self.m = len(self.perms)  # n!\n","        self.perms_as_lists = [list(p) for p in self.perms]\n","\n","        # Set defaults\n","        if max_length is None:\n","            max_length = int((n/2) * math.factorial(n))\n","        if max_steps is None:\n","            max_steps = 3*max_length\n","\n","        self.max_length = max_length\n","        self.max_steps = max_steps\n","        self.alpha_new_perm_reward = alpha_new_perm_reward\n","        self.goal_bonus = goal_bonus\n","        self.length_penalty_at_goal = length_penalty_at_goal\n","\n","        # Internal state\n","        self.string: list[int] = []\n","        self.coverage: np.ndarray = np.zeros(self.m, dtype=bool)\n","        self.step_count: int = 0\n","        self.costs: np.ndarray = np.zeros(self.m, dtype=np.float32)\n","\n","        # Action space: choose one permutation from {0, ..., m-1}\n","        self.action_space = spaces.Discrete(self.m)\n","\n","        # Observation space\n","        self.observation_space = spaces.Dict({\n","            \"coverage\": spaces.MultiBinary(self.m),\n","            \"costs\": spaces.Box(low=0.0, high=float(self.n), shape=(self.m,), dtype=np.float32),\n","            \"length\": spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),\n","        })\n","\n","    def _compute_cost_vector(self) -> np.ndarray:\n","        \"\"\"\n","        Compute the cost vector for all permutations.\n","\n","        Cost[i] = n - overlap(string, perms[i])\n","        where overlap is the maximum overlap length.\n","\n","        Returns:\n","            Cost array of shape (m,)\n","        \"\"\"\n","        costs = np.zeros(self.m, dtype=np.float32)\n","        for i, word in enumerate(self.perms_as_lists):\n","            if len(self.string) == 0:\n","                overlap = 0\n","            else:\n","                overlap = max_overlap(self.string, word)\n","            costs[i] = float(self.n - overlap)\n","        return costs\n","\n","    def _get_observation(self) -> Dict[str, Any]:\n","        \"\"\"Build the current observation.\"\"\"\n","        # Coverage: boolean array\n","        coverage = self.coverage.copy().astype(np.int8)\n","\n","        # Costs: already computed in self.costs\n","        costs = self.costs.copy()\n","\n","        # Length: normalized to [0, 1]\n","        length_norm = np.array([min(1.0, len(self.string) / self.max_length)], dtype=np.float32)\n","\n","        return {\n","            \"coverage\": coverage,\n","            \"costs\": costs,\n","            \"length\": length_norm,\n","        }\n","\n","    def reset(\n","        self,\n","        seed: Optional[int] = None,\n","        options: Optional[dict] = None,\n","    ) -> tuple[Dict[str, Any], Dict[str, Any]]:\n","        \"\"\"Reset the environment.\"\"\"\n","        super().reset(seed=seed)\n","\n","        self.string = []\n","        self.coverage[:] = False\n","        self.step_count = 0\n","        self.costs = self._compute_cost_vector()\n","\n","        obs = self._get_observation()\n","        info = {\"n\": self.n}\n","\n","        return obs, info\n","\n","    def step(self, action: int) -> tuple[Dict[str, Any], float, bool, bool, Dict[str, Any]]:\n","        \"\"\"\n","        Execute one step.\n","\n","        Args:\n","            action: Index of permutation to add (0 to m-1)\n","\n","        Returns:\n","            observation, reward, terminated, truncated, info\n","        \"\"\"\n","        # Validate action\n","        if not self.action_space.contains(action):\n","            raise ValueError(f\"Invalid action: {action}\")\n","\n","        i = int(action)\n","        word = self.perms_as_lists[i]\n","\n","        # Compute overlap and cost\n","        if len(self.string) == 0:\n","            overlap = 0\n","        else:\n","            overlap = max_overlap(self.string, word)\n","        cost = self.n - overlap\n","\n","        # Merge word into string\n","        self.string = merge_with_overlap(self.string, word)\n","        self.step_count += 1\n","\n","        # Update coverage\n","        delta_new_perms = update_coverage_for_string(\n","            string=self.string,\n","            n=self.n,\n","            perms=self.perms,\n","            coverage=self.coverage,\n","            search_window=2 * self.n,  # Only check recent suffix\n","        )\n","\n","        # Compute reward\n","        step_length_penalty = -float(cost)*0.2\n","        new_perm_reward = self.alpha_new_perm_reward * float(delta_new_perms)\n","        reward = step_length_penalty + new_perm_reward\n","\n","        # Check termination conditions\n","        success = False\n","        truncated = False\n","        terminated = False\n","\n","        if self.coverage.sum() == self.m:\n","            # All permutations covered\n","            success = True\n","            terminated = True\n","            final_length = len(self.string)\n","            reward += self.goal_bonus - self.length_penalty_at_goal * final_length\n","        elif len(self.string) > self.max_length or self.step_count >= self.max_steps:\n","            truncated = True\n","            terminated = True\n","            reward-=100\n","        else:\n","            terminated = False\n","\n","        # Recompute cost vector for next step\n","        self.costs = self._compute_cost_vector()\n","\n","        # Build observation\n","        obs = self._get_observation()\n","\n","        # Build info\n","        info = {\n","            \"n\": self.n,\n","            \"step_count\": self.step_count,\n","            \"current_length\": len(self.string),\n","            \"coverage_ratio\": float(self.coverage.sum()) / float(self.m),\n","            \"success\": success,\n","            \"truncated\": truncated,\n","        }\n","\n","        if terminated or truncated:\n","            info[\"final_length\"] = len(self.string)\n","            info[\"sequence\"] = list(self.string)\n","            info[\"covered_permutations\"] = int(self.coverage.sum())\n","\n","        return obs, reward, terminated, truncated, info\n","\n","\n"]},{"cell_type":"code","execution_count":42,"id":"662013c4","metadata":{"id":"662013c4","executionInfo":{"status":"ok","timestamp":1765089446100,"user_tz":-540,"elapsed":42,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/utils/types.py\n","\"\"\"Type definitions for superpermutation RL research.\"\"\"\n","\n","from typing import Literal\n","\n","# Environment type\n","EnvType = Literal[\"symbol\", \"word_cost\"]\n","\n","# Algorithm name\n","AlgoName = Literal[\"ppo\", \"dqn\",\"random\"]\n","\n"]},{"cell_type":"code","execution_count":43,"id":"915422f5","metadata":{"id":"915422f5","executionInfo":{"status":"ok","timestamp":1765089446102,"user_tz":-540,"elapsed":1,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/utils/common.py\n","\"\"\"Common utility functions for superpermutation RL research.\"\"\"\n","\n","import os\n","import json\n","import numpy as np\n","import torch\n","from typing import Dict, Any, Optional\n","import gymnasium as gym\n","\n","\n","\n","\n","def convert_numpy_types(obj: Any) -> Any:\n","    \"\"\"\n","    Convert numpy types to Python native types for JSON serialization.\n","\n","    Args:\n","        obj: Object that may contain numpy types\n","\n","    Returns:\n","        Object with numpy types converted to Python types\n","    \"\"\"\n","    if isinstance(obj, (np.integer, np.intc, np.intp, np.int8,\n","                        np.int16, np.int32, np.int64, np.uint8, np.uint16,\n","                        np.uint32, np.uint64)):\n","        return int(obj)\n","    elif isinstance(obj, (np.floating, np.float16, np.float32, np.float64)):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, dict):\n","        return {key: convert_numpy_types(value) for key, value in obj.items()}\n","    elif isinstance(obj, (list, tuple)):\n","        return [convert_numpy_types(item) for item in obj]\n","    else:\n","        return obj\n","\n","\n","def generate_run_name(\n","    env_type: EnvType,\n","    n: int,\n","    algo_name: AlgoName,\n","    seed: int,\n","    hyperparams: Optional[Dict[str, Any]] = None,\n",") -> str:\n","    \"\"\"\n","    Generate a run name from parameters.\n","\n","    Args:\n","        env_type: Environment type\n","        n: Permutation size\n","        algo_name: Algorithm name\n","        seed: Random seed\n","        hyperparams: Optional hyperparameters dict\n","\n","    Returns:\n","        Run name string\n","    \"\"\"\n","    run_name = f\"{env_type}_n{n}_{algo_name}_seed{seed}\"\n","    if hyperparams:\n","        # Add hyperparam signature to run name\n","        hp_sig = \"_\".join(f\"{k}{v}\" for k, v in sorted(hyperparams.items()))\n","        run_name = f\"{run_name}_{hp_sig}\"\n","    return run_name\n","\n","\n","def create_metadata(\n","    env_type: EnvType,\n","    n: int,\n","    algo_name: AlgoName,\n","    hyperparams: Dict[str, Any],\n","    seed: int,\n","    **kwargs: Any,\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Create metadata dictionary for a run.\n","\n","    Args:\n","        env_type: Environment type\n","        n: Permutation size\n","        algo_name: Algorithm name\n","        hyperparams: Hyperparameters dict\n","        seed: Random seed\n","        **kwargs: Additional metadata fields\n","\n","    Returns:\n","        Metadata dictionary\n","    \"\"\"\n","    metadata = {\n","        \"env_type\": env_type,\n","        \"n\": n,\n","        \"algo_name\": algo_name,\n","        \"hyperparams\": hyperparams,\n","        \"seed\": seed,\n","    }\n","    metadata.update(kwargs)\n","    return metadata\n","\n","\n","def save_metadata(run_dir: str, metadata: Dict[str, Any]) -> None:\n","    \"\"\"\n","    Save metadata to a JSON file.\n","\n","    Args:\n","        run_dir: Run directory path\n","        metadata: Metadata dictionary\n","    \"\"\"\n","    # Convert numpy types to Python native types for JSON serialization\n","    metadata_serializable = convert_numpy_types(metadata)\n","\n","    metadata_path = os.path.join(run_dir, \"metadata.json\")\n","    with open(metadata_path, \"w\") as f:\n","        json.dump(metadata_serializable, f, indent=2)\n","\n","\n","def detect_env_type(env: gym.Env) -> EnvType:\n","    \"\"\"\n","    Detect environment type from an environment instance.\n","\n","    Args:\n","        env: Gymnasium environment\n","\n","    Returns:\n","        Environment type (\"symbol\" or \"word_cost\")\n","    \"\"\"\n","    if hasattr(env, \"costs\"):\n","        return \"word_cost\"\n","    elif hasattr(env, \"n\") and hasattr(env, \"perms\"):\n","        return \"symbol\"\n","    else:\n","        # Fallback: check class name\n","        class_name = env.__class__.__name__\n","        if \"Word\" in class_name or \"word\" in class_name.lower():\n","            return \"word_cost\"\n","        else:\n","            return \"symbol\"\n","\n","\n","def set_all_seeds(seed: int) -> None:\n","    \"\"\"\n","    Set all random seeds for reproducibility.\n","\n","    Args:\n","        seed: Random seed value\n","    \"\"\"\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n"]},{"cell_type":"code","execution_count":44,"id":"5fd9307b","metadata":{"id":"5fd9307b","executionInfo":{"status":"ok","timestamp":1765089446110,"user_tz":-540,"elapsed":7,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[],"source":["# Source: /content/train_one.py\n","\"\"\"Train a single RL run.\"\"\"\n","\n","import os\n","import time\n","import numpy as np\n","import torch\n","from stable_baselines3 import PPO, A2C, DQN\n","from stable_baselines3.common.logger import configure\n","from sb3_contrib import MaskablePPO\n","from sb3_contrib.common.wrappers import ActionMasker\n","from gymnasium import spaces\n","\n","\n","\n","\n","ALGO_MAP = {\n","    \"ppo\": PPO,\n","    \"dqn\": DQN,  # basic: dueling=False\n","}\n","\n","\n","def word_env_mask_fn(obs) -> np.ndarray:\n","    \"\"\"\n","    Action mask function for WordCostSuperpermEnv.\n","\n","    Masks out actions where:\n","    - The permutation is already covered AND\n","    - The cost equals the maximum cost (n, meaning zero overlap)\n","\n","    Args:\n","        obs: Observation dict from WordCostSuperpermEnv\n","\n","    Returns:\n","        Boolean mask of shape (m,) where False means invalid action\n","    \"\"\"\n","    coverage = obs[\"coverage\"]\n","    costs = obs[\"costs\"]\n","\n","    # Maximum cost should be n (alphabet size), which occurs when overlap is 0\n","    # We can infer n from the maximum cost value\n","    max_cost = np.max(costs)\n","\n","    # Mask: allow all actions by default\n","    mask = np.ones(len(coverage), dtype=bool)\n","\n","    # Mask out covered permutations with maximum cost (zero overlap, already covered)\n","    # This prevents adding a permutation that's already covered with no benefit\n","    mask = ~((coverage == 1) & (np.abs(costs - max_cost) < 0.01))\n","\n","    return mask\n","\n","\n","def make_env(env_type: EnvType, n: int, use_mask: bool = False):\n","    \"\"\"\n","    Create an environment.\n","\n","    Args:\n","        env_type: \"symbol\" or \"word_cost\"\n","        n: Alphabet size\n","        use_mask: Whether to apply action masking (for MaskablePPO on WordEnv)\n","\n","    Returns:\n","        Gymnasium environment\n","    \"\"\"\n","    if env_type == \"symbol\":\n","        env = SymbolSuperpermEnv(n=n)\n","        return env\n","    elif env_type == \"word_cost\":\n","        env = WordCostSuperpermEnv(n=n)\n","        if use_mask:\n","            env = ActionMasker(env, word_env_mask_fn)\n","        return env\n","    else:\n","        raise ValueError(f\"Unknown env_type: {env_type}\")\n","\n","\n","def train_one_run(\n","    env_type: EnvType,\n","    n: int,\n","    algo_name: AlgoName,\n","    hyperparams: dict,\n","    seed: int,\n","    total_timesteps: int,\n","    log_root: str = \"logs\",\n",") -> str:\n","    \"\"\"\n","    Train a single RL run.\n","\n","    Args:\n","        env_type: \"symbol\" or \"word_cost\"\n","        n: Alphabet size\n","        algo_name: Algorithm name (\"ppo\", \"maskable_ppo\", \"a2c\", \"dqn\", \"dqn_dueling\")\n","        hyperparams: Hyperparameters dict\n","        seed: Random seed\n","        total_timesteps: Total training timesteps\n","        log_root: Root directory for logs\n","    \"\"\"\n","    # Create run directory\n","    run_name = generate_run_name(env_type, n, algo_name, seed, hyperparams)\n","    run_dir = os.path.join(log_root, run_name)\n","    os.makedirs(run_dir, exist_ok=True)\n","\n","    # Create environment\n","    use_mask = (algo_name == \"maskable_ppo\" and env_type == \"word_cost\")\n","    env = make_env(env_type, n, use_mask=use_mask)\n","\n","    # Set seeds\n","    env.reset(seed=seed)\n","    set_all_seeds(seed)\n","\n","    # Get algorithm class\n","    AlgoClass = ALGO_MAP.get(algo_name)\n","    if AlgoClass is None:\n","        raise ValueError(f\"Unknown algorithm: {algo_name}\")\n","\n","    # Determine device (GPU if available, else CPU)\n","    cuda_available = torch.cuda.is_available()\n","    if cuda_available:\n","        device = \"cuda\"\n","        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","    else:\n","        device = \"cpu\"\n","        print(\"CUDA not available, using CPU\")\n","        print(\"Note: To use GPU, ensure PyTorch with CUDA support is installed\")\n","\n","    # Check observation space type (handle wrapped environments)\n","    obs_space = env.observation_space\n","    # If wrapped, get the actual observation space\n","    while hasattr(obs_space, \"observation_space\"):\n","        obs_space = obs_space.observation_space\n","\n","    # Determine policy type\n","    # Check if observation space is a Dict (not a Python dict, but gymnasium.spaces.Dict)\n","    if isinstance(obs_space, spaces.Dict):\n","        policy = \"MultiInputPolicy\"\n","    else:\n","        policy = \"MlpPolicy\"\n","\n","    # Configure policy kwargs\n","    policy_kwargs = {}\n","    if algo_name == \"dqn\":\n","        policy_kwargs = {\"policy_kwargs\": {\"dueling\": False}}\n","    elif algo_name == \"dqn_dueling\":\n","        policy_kwargs = {\"policy_kwargs\": {\"dueling\": True}}\n","\n","    # Configure SB3 logger\n","    logger = configure(run_dir, [\"csv\", \"tensorboard\"])\n","\n","    # Create model\n","    model = AlgoClass(\n","        policy,\n","        env,\n","        verbose=1,\n","        seed=seed,\n","        device=device,\n","        tensorboard_log=os.path.join(run_dir, \"tensorboard\"),\n","        **hyperparams,\n","        **policy_kwargs,\n","    )\n","    model.set_logger(logger)\n","\n","    # Create callback (save episodes for successful runs)\n","    episodes_dir = os.path.join(run_dir, \"episodes\")\n","    callback = SuperpermEpisodeCallback(verbose=1, save_episodes_dir=episodes_dir)\n","\n","    # Train\n","    start_time = time.time()\n","    model.learn(\n","        total_timesteps=total_timesteps,\n","        callback=callback,\n","        log_interval=10,\n","    )\n","    wall_time = time.time() - start_time\n","\n","    # Save model\n","    model.save(os.path.join(run_dir, \"model\"))\n","\n","    # Save metadata\n","    metadata = create_metadata(\n","        env_type=env_type,\n","        n=n,\n","        algo_name=algo_name,\n","        hyperparams=hyperparams,\n","        seed=seed,\n","        total_timesteps=total_timesteps,\n","        wall_time=wall_time,\n","    )\n","    save_metadata(run_dir, metadata)\n","\n","    return run_dir\n","\n"]},{"cell_type":"code","execution_count":45,"id":"c8bcdc9d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8bcdc9d","executionInfo":{"status":"ok","timestamp":1765089446165,"user_tz":-540,"elapsed":37,"user":{"displayName":"cyclone","userId":"12166826990540214817"}},"outputId":"7aff9ddc-8122-4abe-efa8-0c5a531b967d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Log directory logs does not exist.\n","Found 0 runs\n","Saved metrics summary to metrics/metrics_summary.csv\n","Saved metrics summary to metrics/metrics_summary.json\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}],"source":["# Source: /content/metrics.py\n","\"\"\"Aggregate metrics and extract top-3 superpermutations.\"\"\"\n","\n","import os\n","import json\n","import csv\n","import ast\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","from typing import Dict, List, Any, Tuple\n","from collections import defaultdict\n","\n","\n","\n","\n","def scan_logs(log_root: str = \"logs\") -> List[Dict[str, Any]]:\n","    \"\"\"\n","    Scan logs directory for all run directories.\n","\n","    Returns:\n","        List of run metadata dicts\n","    \"\"\"\n","    runs = []\n","    log_path = Path(log_root)\n","\n","    if not log_path.exists():\n","        print(f\"Log directory {log_root} does not exist.\")\n","        return runs\n","\n","    for run_dir in log_path.iterdir():\n","        if not run_dir.is_dir():\n","            continue\n","\n","        metadata_path = run_dir / \"metadata.json\"\n","        progress_path = run_dir / \"progress.csv\"\n","\n","        if not progress_path.exists():\n","            continue\n","\n","        metadata = {}\n","        if metadata_path.exists():\n","            with open(metadata_path, \"r\") as f:\n","                metadata = json.load(f)\n","\n","        runs.append({\n","            \"run_dir\": str(run_dir),\n","            \"run_name\": run_dir.name,\n","            \"metadata\": metadata,\n","            \"progress_path\": str(progress_path),\n","        })\n","\n","    return runs\n","\n","\n","def load_progress_csv(csv_path: str) -> pd.DataFrame:\n","    \"\"\"Load progress CSV file.\"\"\"\n","    try:\n","        df = pd.read_csv(csv_path)\n","        return df\n","    except Exception as e:\n","        print(f\"Error loading {csv_path}: {e}\")\n","        return pd.DataFrame()\n","\n","\n","def extract_sequences_from_progress(df: pd.DataFrame, run_dir: str) -> List[Dict[str, Any]]:\n","    \"\"\"\n","    Extract sequences from progress CSV.\n","\n","    Note: progress.csv may not have sequences directly.\n","    We'll need to check if sequences are stored elsewhere or reconstruct from episodes.\n","    For now, we'll return empty list and note that sequences should be extracted\n","    from episode info during training.\n","    \"\"\"\n","    sequences = []\n","\n","    # If progress.csv has sequence column, use it\n","    if \"sequence\" in df.columns:\n","        for idx, row in df.iterrows():\n","            if row.get(\"success\", 0) == 1:\n","                try:\n","                    seq_str = row[\"sequence\"]\n","                    if isinstance(seq_str, str):\n","                        # Try to parse as Python literal (list)\n","                        seq = ast.literal_eval(seq_str)\n","                    else:\n","                        seq = seq_str\n","                    sequences.append({\n","                        \"episode\": int(row.get(\"episode\", idx)),\n","                        \"final_length\": int(row.get(\"final_length\", 0)),\n","                        \"episode_return\": float(row.get(\"episode_return\", 0.0)),\n","                        \"sequence\": seq,\n","                    })\n","                except (ValueError, SyntaxError, TypeError):\n","                    # Skip if parsing fails\n","                    pass\n","\n","    return sequences\n","\n","\n","def extract_sequences_from_episodes(run_dir: str, n: int) -> List[Dict[str, Any]]:\n","    \"\"\"\n","    Extract sequences from episode logs.\n","\n","    Looks for episode JSON files in the episodes/ subdirectory.\n","    \"\"\"\n","    sequences = []\n","    run_path = Path(run_dir)\n","\n","    # Check for episode files in episodes/ subdirectory\n","    episodes_dir = run_path / \"episodes\"\n","    if episodes_dir.exists():\n","        episode_files = list(episodes_dir.glob(\"episode_*.json\"))\n","        for ep_file in sorted(episode_files):\n","            try:\n","                with open(ep_file, \"r\") as f:\n","                    ep_data = json.load(f)\n","                    if ep_data.get(\"success\", False) and \"sequence\" in ep_data:\n","                        sequences.append({\n","                            \"episode\": ep_data.get(\"episode\", 0),\n","                            \"final_length\": ep_data.get(\"final_length\", 0),\n","                            \"episode_return\": ep_data.get(\"episode_return\", 0.0),\n","                            \"sequence\": ep_data[\"sequence\"],\n","                        })\n","            except Exception as e:\n","                print(f\"Error reading {ep_file}: {e}\")\n","                pass\n","\n","    return sequences\n","\n","\n","def get_top3_superperms(\n","    sequences: List[Dict[str, Any]],\n","    n: int,\n",") -> List[Dict[str, Any]]:\n","    \"\"\"\n","    Get top-3 shortest distinct superpermutations.\n","\n","    Args:\n","        sequences: List of sequence dicts with keys: episode, final_length, episode_return, sequence\n","        n: Alphabet size\n","\n","    Returns:\n","        List of top-3 superpermutation dicts\n","    \"\"\"\n","    if not sequences:\n","        return []\n","\n","    # Canonicalize and deduplicate\n","    seen = set()\n","    unique_seqs = []\n","\n","    for seq_data in sequences:\n","        seq = seq_data[\"sequence\"]\n","        if not isinstance(seq, list):\n","            continue\n","\n","        canonical = tuple(canonicalize_superperm(seq, n))\n","        if canonical not in seen:\n","            seen.add(canonical)\n","            unique_seqs.append({\n","                \"canonical_sequence\": list(canonical),\n","                \"original_sequence\": seq,\n","                \"final_length\": seq_data[\"final_length\"],\n","                \"episode_return\": seq_data.get(\"episode_return\", 0.0),\n","                \"episode\": seq_data.get(\"episode\", 0),\n","            })\n","\n","    # Sort by final_length, then by episode_return (descending)\n","    unique_seqs.sort(key=lambda x: (x[\"final_length\"], -x[\"episode_return\"]))\n","\n","    # Take top 3\n","    top3 = unique_seqs[:3]\n","\n","    # Add rank\n","    for i, item in enumerate(top3, 1):\n","        item[\"rank\"] = i\n","\n","    return top3\n","\n","\n","def compute_run_metrics(df: pd.DataFrame) -> Dict[str, Any]:\n","    \"\"\"Compute aggregated metrics for a run.\"\"\"\n","    if df.empty:\n","        return {}\n","\n","    metrics = {}\n","\n","    # Final length statistics\n","    if \"final_length\" in df.columns:\n","        metrics[\"mean_final_length\"] = float(df[\"final_length\"].mean())\n","        metrics[\"min_final_length\"] = float(df[\"final_length\"].min())\n","        metrics[\"max_final_length\"] = float(df[\"final_length\"].max())\n","        metrics[\"std_final_length\"] = float(df[\"final_length\"].std())\n","\n","    # Success rate\n","    if \"success\" in df.columns:\n","        success_count = int(df[\"success\"].sum())\n","        total_episodes = len(df)\n","        metrics[\"success_rate\"] = float(success_count / total_episodes) if total_episodes > 0 else 0.0\n","        metrics[\"success_count\"] = success_count\n","        metrics[\"total_episodes\"] = total_episodes\n","\n","    # Coverage ratio\n","    if \"coverage_ratio\" in df.columns:\n","        metrics[\"mean_coverage_ratio\"] = float(df[\"coverage_ratio\"].mean())\n","\n","    # Episode steps\n","    if \"episode_steps\" in df.columns:\n","        metrics[\"mean_episode_steps\"] = float(df[\"episode_steps\"].mean())\n","\n","    # Episode return\n","    if \"episode_return\" in df.columns:\n","        metrics[\"mean_episode_return\"] = float(df[\"episode_return\"].mean())\n","        metrics[\"std_episode_return\"] = float(df[\"episode_return\"].std())\n","        metrics[\"min_episode_return\"] = float(df[\"episode_return\"].min())\n","        metrics[\"max_episode_return\"] = float(df[\"episode_return\"].max())\n","\n","    # Steps to first success\n","    if \"success\" in df.columns and \"episode_steps\" in df.columns:\n","        success_episodes = df[df[\"success\"] == 1]\n","        if not success_episodes.empty:\n","            first_success_idx = success_episodes.index[0]\n","            metrics[\"episodes_to_first_success\"] = int(first_success_idx)\n","            # Cumulative steps to first success\n","            metrics[\"steps_to_first_success\"] = int(df.loc[:first_success_idx, \"episode_steps\"].sum())\n","        else:\n","            metrics[\"episodes_to_first_success\"] = None\n","            metrics[\"steps_to_first_success\"] = None\n","\n","    return metrics\n","\n","\n","def update_metrics_for_run(\n","    run_dir: str,\n","    log_root: str = \"logs\",\n","    output_dir: str = \"metrics\",\n",") -> None:\n","    \"\"\"\n","    Update metrics for a single run (incremental update).\n","\n","    This function updates the aggregated metrics after a single run completes.\n","    It reads existing metrics and updates them with the new run's data.\n","\n","    Args:\n","        run_dir: Directory of the completed run\n","        log_root: Root directory containing run logs\n","        output_dir: Directory to save aggregated metrics\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Load metadata and progress for this run\n","    run_path = Path(run_dir)\n","    metadata_path = run_path / \"metadata.json\"\n","    progress_path = run_path / \"progress.csv\"\n","\n","    if not progress_path.exists():\n","        return\n","\n","    metadata = {}\n","    if metadata_path.exists():\n","        with open(metadata_path, \"r\") as f:\n","            metadata = json.load(f)\n","\n","    env_type = metadata.get(\"env_type\", \"unknown\")\n","    n = metadata.get(\"n\", 0)\n","    algo_name = metadata.get(\"algo_name\", \"unknown\")\n","    hyperparams = metadata.get(\"hyperparams\", {})\n","\n","    # Create group key\n","    hp_sig = \"_\".join(f\"{k}{v}\" for k, v in sorted(hyperparams.items())) if hyperparams else \"default\"\n","    group_key = (env_type, n, algo_name, hp_sig)\n","    group_name = f\"{env_type}_n{n}_{algo_name}_{hp_sig}\"\n","\n","    # Load existing summary if exists\n","    summary_path = os.path.join(output_dir, \"metrics_summary.json\")\n","    existing_summaries = []\n","    if os.path.exists(summary_path):\n","        with open(summary_path, \"r\") as f:\n","            existing_summaries = json.load(f)\n","\n","    # Find existing summary for this group\n","    existing_summary = None\n","    existing_idx = None\n","    for idx, summary in enumerate(existing_summaries):\n","        if (summary.get(\"env_type\") == env_type and\n","            summary.get(\"n\") == n and\n","            summary.get(\"algo_name\") == algo_name and\n","            summary.get(\"hyperparams\") == hp_sig):\n","            existing_summary = summary\n","            existing_idx = idx\n","            break\n","\n","    # Get all runs in this group\n","    all_runs = scan_logs(log_root)\n","    group_runs = []\n","    for run in all_runs:\n","        run_meta = run[\"metadata\"]\n","        run_env_type = run_meta.get(\"env_type\", \"unknown\")\n","        run_n = run_meta.get(\"n\", 0)\n","        run_algo = run_meta.get(\"algo_name\", \"unknown\")\n","        run_hp = run_meta.get(\"hyperparams\", {})\n","        run_hp_sig = \"_\".join(f\"{k}{v}\" for k, v in sorted(run_hp.items())) if run_hp else \"default\"\n","\n","        if (run_env_type == env_type and run_n == n and\n","            run_algo == algo_name and run_hp_sig == hp_sig):\n","            group_runs.append(run)\n","\n","    # Aggregate metrics for this group\n","    all_metrics = []\n","    all_sequences = []\n","\n","    for run in group_runs:\n","        df = load_progress_csv(run[\"progress_path\"])\n","        if df.empty:\n","            continue\n","\n","        # Compute run-level metrics\n","        run_metrics = compute_run_metrics(df)\n","        run_metrics[\"run_name\"] = run[\"run_name\"]\n","        run_metrics[\"seed\"] = run[\"metadata\"].get(\"seed\", None)\n","        run_metrics[\"wall_time\"] = run[\"metadata\"].get(\"wall_time\", None)\n","        all_metrics.append(run_metrics)\n","\n","        # Extract sequences\n","        sequences = extract_sequences_from_progress(df, run[\"run_dir\"])\n","        if not sequences:\n","            sequences = extract_sequences_from_episodes(run[\"run_dir\"], n)\n","\n","        for seq in sequences:\n","            seq[\"run_name\"] = run[\"run_name\"]\n","            all_sequences.append(seq)\n","\n","    if not all_metrics:\n","        return\n","\n","    # Aggregate across runs\n","    metrics_df = pd.DataFrame(all_metrics)\n","\n","    summary = {\n","        \"env_type\": env_type,\n","        \"n\": n,\n","        \"algo_name\": algo_name,\n","        \"hyperparams\": hp_sig,\n","        \"num_runs\": len(group_runs),\n","        \"mean_final_length\": float(metrics_df[\"mean_final_length\"].mean()) if \"mean_final_length\" in metrics_df.columns else None,\n","        \"min_final_length\": float(metrics_df[\"min_final_length\"].min()) if \"min_final_length\" in metrics_df.columns else None,\n","        \"max_final_length\": float(metrics_df[\"max_final_length\"].max()) if \"max_final_length\" in metrics_df.columns else None,\n","        \"mean_success_rate\": float(metrics_df[\"success_rate\"].mean()) if \"success_rate\" in metrics_df.columns else None,\n","        \"mean_coverage_ratio\": float(metrics_df[\"mean_coverage_ratio\"].mean()) if \"mean_coverage_ratio\" in metrics_df.columns else None,\n","        \"mean_episode_steps\": float(metrics_df[\"mean_episode_steps\"].mean()) if \"mean_episode_steps\" in metrics_df.columns else None,\n","        \"mean_episode_return\": float(metrics_df[\"mean_episode_return\"].mean()) if \"mean_episode_return\" in metrics_df.columns else None,\n","        \"total_wall_time\": float(metrics_df[\"wall_time\"].sum()) if \"wall_time\" in metrics_df.columns else None,\n","    }\n","\n","    # Update or add summary\n","    if existing_idx is not None:\n","        existing_summaries[existing_idx] = summary\n","    else:\n","        existing_summaries.append(summary)\n","\n","    # Save updated summary\n","    with open(summary_path, \"w\") as f:\n","        json.dump(existing_summaries, f, indent=2)\n","\n","    # Save CSV version\n","    summary_df = pd.DataFrame(existing_summaries)\n","    csv_path = os.path.join(output_dir, \"metrics_summary.csv\")\n","    summary_df.to_csv(csv_path, index=False)\n","\n","    # Extract and save top-3 superpermutations for this group\n","    top3 = get_top3_superperms(all_sequences, n)\n","    if top3:\n","        top3_path = os.path.join(output_dir, f\"{group_name}_top3_superperms.json\")\n","        with open(top3_path, \"w\") as f:\n","            json.dump(top3, f, indent=2)\n","        print(f\"Updated metrics and top-3 for {group_name} ({len(group_runs)} runs)\")\n","\n","\n","def aggregate_metrics(log_root: str = \"logs\", output_dir: str = \"metrics\") -> None:\n","    \"\"\"\n","    Aggregate metrics from all runs and extract top-3 superpermutations.\n","\n","    Args:\n","        log_root: Root directory containing run logs\n","        output_dir: Directory to save aggregated metrics\n","    \"\"\"\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    runs = scan_logs(log_root)\n","    print(f\"Found {len(runs)} runs\")\n","\n","    # Group runs by (env_type, n, algo_name, hyperparams)\n","    grouped_runs = defaultdict(list)\n","\n","    for run in runs:\n","        metadata = run[\"metadata\"]\n","        env_type = metadata.get(\"env_type\", \"unknown\")\n","        n = metadata.get(\"n\", 0)\n","        algo_name = metadata.get(\"algo_name\", \"unknown\")\n","        hyperparams = metadata.get(\"hyperparams\", {})\n","\n","        # Create group key\n","        hp_sig = \"_\".join(f\"{k}{v}\" for k, v in sorted(hyperparams.items())) if hyperparams else \"default\"\n","        group_key = (env_type, n, algo_name, hp_sig)\n","\n","        grouped_runs[group_key].append(run)\n","\n","    # Aggregate metrics for each group\n","    summary_rows = []\n","\n","    for group_key, group_runs in grouped_runs.items():\n","        env_type, n, algo_name, hp_sig = group_key\n","\n","        # Aggregate metrics across all runs in group\n","        all_metrics = []\n","        all_sequences = []\n","\n","        for run in group_runs:\n","            df = load_progress_csv(run[\"progress_path\"])\n","            if df.empty:\n","                continue\n","\n","            # Compute run-level metrics\n","            run_metrics = compute_run_metrics(df)\n","            run_metrics[\"run_name\"] = run[\"run_name\"]\n","            run_metrics[\"seed\"] = run[\"metadata\"].get(\"seed\", None)\n","            run_metrics[\"wall_time\"] = run[\"metadata\"].get(\"wall_time\", None)\n","            all_metrics.append(run_metrics)\n","\n","            # Extract sequences (try multiple methods)\n","            sequences = extract_sequences_from_progress(df, run[\"run_dir\"])\n","            if not sequences:\n","                sequences = extract_sequences_from_episodes(run[\"run_dir\"], n)\n","\n","            for seq in sequences:\n","                seq[\"run_name\"] = run[\"run_name\"]\n","                all_sequences.append(seq)\n","\n","        if not all_metrics:\n","            continue\n","\n","        # Aggregate across runs\n","        metrics_df = pd.DataFrame(all_metrics)\n","\n","        summary = {\n","            \"env_type\": env_type,\n","            \"n\": n,\n","            \"algo_name\": algo_name,\n","            \"hyperparams\": hp_sig,\n","            \"num_runs\": len(group_runs),\n","            \"mean_final_length\": float(metrics_df[\"mean_final_length\"].mean()) if \"mean_final_length\" in metrics_df.columns else None,\n","            \"min_final_length\": float(metrics_df[\"min_final_length\"].min()) if \"min_final_length\" in metrics_df.columns else None,\n","            \"max_final_length\": float(metrics_df[\"max_final_length\"].max()) if \"max_final_length\" in metrics_df.columns else None,\n","            \"mean_success_rate\": float(metrics_df[\"success_rate\"].mean()) if \"success_rate\" in metrics_df.columns else None,\n","            \"mean_coverage_ratio\": float(metrics_df[\"mean_coverage_ratio\"].mean()) if \"mean_coverage_ratio\" in metrics_df.columns else None,\n","            \"mean_episode_steps\": float(metrics_df[\"mean_episode_steps\"].mean()) if \"mean_episode_steps\" in metrics_df.columns else None,\n","            \"mean_episode_return\": float(metrics_df[\"mean_episode_return\"].mean()) if \"mean_episode_return\" in metrics_df.columns else None,\n","            \"total_wall_time\": float(metrics_df[\"wall_time\"].sum()) if \"wall_time\" in metrics_df.columns else None,\n","        }\n","\n","        summary_rows.append(summary)\n","\n","        # Extract top-3 superpermutations for this group\n","        top3 = get_top3_superperms(all_sequences, n)\n","\n","        if top3:\n","            # Save top-3 for this group\n","            group_name = f\"{env_type}_n{n}_{algo_name}_{hp_sig}\"\n","            top3_path = os.path.join(output_dir, f\"{group_name}_top3_superperms.json\")\n","            with open(top3_path, \"w\") as f:\n","                json.dump(top3, f, indent=2)\n","            print(f\"Saved top-3 superpermutations for {group_name}\")\n","\n","    # Save summary CSV\n","    summary_df = pd.DataFrame(summary_rows)\n","    summary_path = os.path.join(output_dir, \"metrics_summary.csv\")\n","    summary_df.to_csv(summary_path, index=False)\n","    print(f\"Saved metrics summary to {summary_path}\")\n","\n","    # Also save as JSON\n","    summary_json_path = os.path.join(output_dir, \"metrics_summary.json\")\n","    with open(summary_json_path, \"w\") as f:\n","        json.dump(summary_rows, f, indent=2)\n","    print(f\"Saved metrics summary to {summary_json_path}\")\n","\n","\n","if __name__ == \"__main__\":\n","    aggregate_metrics()\n","\n"]},{"cell_type":"code","execution_count":46,"id":"e52afbcd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e52afbcd","outputId":"bfbb09ab-cc41-4698-80f7-baf5690f76aa","executionInfo":{"status":"ok","timestamp":1765100325294,"user_tz":-540,"elapsed":10879123,"user":{"displayName":"cyclone","userId":"12166826990540214817"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: NVIDIA L4\n","Using cuda device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Completed: word_cost_n5_ppo_seed0 (1 total runs)\n","Using GPU: NVIDIA L4\n","Using cuda device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Completed: symbol_n5_ppo_seed0 (2 total runs)\n","\n","Sweep complete! Total runs: 2\n","\n","Aggregating metrics...\n","Found 2 runs\n","Saved top-3 superpermutations for symbol_n5_ppo_gamma0.99_learning_rate0.0002\n","Saved metrics summary to metrics/metrics_summary.csv\n","Saved metrics summary to metrics/metrics_summary.json\n","Metrics aggregation complete!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}],"source":["# Source: /content/sweep.py\n","\"\"\"Run full experiment sweep over all combinations.\"\"\"\n","\n","import os\n","import itertools\n","\n","\n","\n","def generate_hyperparam_combinations(hyper_grid: dict) -> list[dict]:\n","    \"\"\"Generate all combinations of hyperparameters.\"\"\"\n","    if not hyper_grid:\n","        return [{}]\n","\n","    keys = list(hyper_grid.keys())\n","    values = list(hyper_grid.values())\n","    combinations = []\n","    for combo in itertools.product(*values):\n","        combinations.append(dict(zip(keys, combo)))\n","    return combinations\n","\n","\n","def run_sweep(log_root: str = \"logs\") -> None:\n","    \"\"\"Run the full experiment sweep.\"\"\"\n","    total_runs = 0\n","\n","    for n in N_LIST:\n","        for env_type in ENV_TYPES:\n","            for algo_name in ALGOS:\n","                # Check if should skip this combination\n","                if should_skip(algo_name, env_type, n):\n","                    print(f\"Skipping {algo_name} for {env_type} n={n} (skip condition)\")\n","                    continue\n","\n","                if algo_name in [\"random\", \"greedy\"]:\n","                    # Non-learning baselines\n","                    for seed in SEEDS:\n","                        run_name = generate_run_name(env_type, n, algo_name, seed, None)\n","                        run_dir = os.path.join(log_root, run_name)\n","                        os.makedirs(run_dir, exist_ok=True)\n","\n","                        # Create environment using common function\n","                        env = make_env(env_type, n, use_mask=False)\n","\n","                        # Run baseline\n","                        if algo_name == \"random\":\n","                            run_random(\n","                                env=env,\n","                                total_episodes=BASELINE_EPISODES[\"random\"],\n","                                max_steps_per_episode=env.max_steps,\n","                                log_dir=run_dir,\n","                                seed=seed,\n","                            )\n","                        elif algo_name == \"greedy\":\n","                            run_greedy(\n","                                env=env,\n","                                total_episodes=BASELINE_EPISODES[\"greedy\"],\n","                                max_steps_per_episode=env.max_steps,\n","                                log_dir=run_dir,\n","                                seed=seed,\n","                            )\n","\n","                        total_runs += 1\n","                        print(f\"Completed: {run_name} ({total_runs} total runs)\")\n","\n","                else:\n","                    # RL algorithms\n","                    # Get hyperparameter combinations\n","                    hyper_grid = HYPER_GRIDS.get(algo_name, {})\n","                    hyper_combos = generate_hyperparam_combinations(hyper_grid)\n","\n","                    # Get timesteps for this algorithm\n","                    total_timesteps = TIMESTEPS.get(algo_name)\n","                    if total_timesteps is None:\n","                        print(f\"Warning: No timesteps defined for {algo_name}, skipping\")\n","                        continue\n","\n","                    for hyperparams in hyper_combos:\n","                        for seed in SEEDS:\n","                            try:\n","                                run_dir = train_one_run(\n","                                    env_type=env_type,\n","                                    n=n,\n","                                    algo_name=algo_name,\n","                                    hyperparams=hyperparams,\n","                                    seed=seed,\n","                                    total_timesteps=total_timesteps,\n","                                    log_root=log_root,\n","                                )\n","                                total_runs += 1\n","                                print(f\"Completed: {env_type}_n{n}_{algo_name}_seed{seed} ({total_runs} total runs)\")\n","                            except Exception as e:\n","                                print(f\"Error in {env_type}_n{n}_{algo_name}_seed{seed}: {e}\")\n","                                continue\n","\n","    print(f\"\\nSweep complete! Total runs: {total_runs}\")\n","\n","    # Aggregate metrics after all runs are complete\n","    print(\"\\nAggregating metrics...\")\n","    try:\n","        aggregate_metrics(log_root=log_root)\n","        print(\"Metrics aggregation complete!\")\n","    except Exception as e:\n","        print(f\"Error aggregating metrics: {e}\")\n","\n","\n","if __name__ == \"__main__\":\n","    run_sweep()\n","\n","\n"]},{"cell_type":"code","source":["!zip -r logs.zip logs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTokCakAhX4X","executionInfo":{"status":"ok","timestamp":1765100325357,"user_tz":-540,"elapsed":62,"user":{"displayName":"cyclone","userId":"12166826990540214817"}},"outputId":"cfcb8898-41bb-417f-8ba7-b94e46499718"},"id":"OTokCakAhX4X","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: logs/ (stored 0%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/ (stored 0%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/model.zip (stored 0%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/ (stored 0%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/episode_7162.json (deflated 82%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/episode_6863.json (deflated 81%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/episode_7085.json (deflated 82%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/episode_7183.json (deflated 82%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/episode_6723.json (deflated 82%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/events.out.tfevents.1765094783.fe29f4c9841d.1256.4 (deflated 76%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/metadata.json (deflated 31%)\n","  adding: logs/symbol_n5_ppo_seed0_gamma0.99_learning_rate0.0002/progress.csv (deflated 63%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/ (stored 0%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/model.zip (stored 0%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/episodes/ (stored 0%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/events.out.tfevents.1765089446.fe29f4c9841d.1256.3 (deflated 75%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/metadata.json (deflated 31%)\n","  adding: logs/word_cost_n5_ppo_seed0_gamma0.99_learning_rate0.0002/progress.csv (deflated 59%)\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}